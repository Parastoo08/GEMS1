{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470d06e1-caf1-49c4-a4f0-7b368457e602",
   "metadata": {},
   "source": [
    "# Practical 4 - Seismic attribute analysis\n",
    "\n",
    "This notebook aims to build on your investigation of 3D seismic volumes from practical 3 by providing methods which we can use to enhance the identification of certain geological/environmental features. This is achieved through seismic attributes, attributes use some mathematical calculation of the data to enhance features, very similar to image processing techniques. \n",
    "\n",
    "**Learning Objectives**:\n",
    "\n",
    "1)\tUnderstand that modern seismic data analysis involves calculating seismic attributes to reveal features more clearly\n",
    "2)\tUnderstand that new attributes can be designed or multiple attributes combined to improve imaging\n",
    "3)\tGive you an appreciation that modern seismic data analysis will require the development of more sophisticated data analysis techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50b6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee066981-d6fd-47e2-95b8-aa757d21df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import segyio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66430fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67498d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from mayavi import mlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e29b4e-7d4f-4db0-aa43-1be48e92d208",
   "metadata": {},
   "source": [
    "### 4.1 Explore a new 3D seismic data volume\n",
    "\n",
    "We are going to start this exercise by loading a new 3D seismic data volume- Thebe_rift_faults. As we discussed in  lecture 6 this dataset comes from offshore NW Australia and shows some great examples of faults. This seismic datsets has time as the z-axis (ie it has not been depth converted yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b0185-2e09-46b3-a514-2f25a40f8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_segy = 'data/Thebe_rift_faults'\n",
    "f = segyio.open(base_segy, ignore_geometry= True) #opens files like python default open call , assumes a well-structured 3D volume, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e7ba2-efa3-4974-be1a-fb208e33483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (segyio.tools.wrap(f.text[0])) #show text header to understand file better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbe21f-3fd1-4570-8e13-6bef7f5a65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = segyio.tools.cube(base_segy) #extremely easy for well structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed2aaa-0d8b-4e0e-be4a-86044050129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore3d(data_cube):\n",
    "    \"\"\"\n",
    "    visualise data volume\n",
    "    \"\"\"\n",
    "    source = mlab.pipeline.scalar_field(data_cube)\n",
    "    source.spacing = [1, 1, -1]\n",
    "    vm = np.percentile(data_cube, 95) #may need to play a little with the 95\n",
    "\n",
    "    nx, ny, nz = data_cube.shape\n",
    "    mlab.pipeline.image_plane_widget(source, plane_orientation='x_axes', \n",
    "                                     slice_index=nx//2, colormap='coolwarm', vmin=-vm, vmax=vm)\n",
    "    mlab.pipeline.image_plane_widget(source, plane_orientation='y_axes', \n",
    "                                     slice_index=ny//2, colormap='coolwarm', vmin=-vm, vmax=vm)\n",
    "    mlab.pipeline.image_plane_widget(source, plane_orientation='z_axes', \n",
    "                                     slice_index=nz//2, colormap='coolwarm', vmin=-vm, vmax=vm)\n",
    "    mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814635e-9303-4b03-a96d-d771d4b3cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore3d(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265be7bf-7206-439e-a1bd-79f0681af3d4",
   "metadata": {},
   "source": [
    "**Ex 1: Spend some time looking through this data volume like you did in Exercise 3. Do you identify any interesting features that you recognise from the lecture 5 notes? If so, show some examples below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889440b-9836-4145-a340-eb72277538ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ef93c24-2fef-4d15-a866-efd29aa2a82e",
   "metadata": {},
   "source": [
    "In the next part of the exercise you are going to use seismic attributes to try and highlight these geolgical features even further..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc0ff6-02e0-465d-9f7b-93e76f47f1ca",
   "metadata": {},
   "source": [
    "## 4.1.1. Attribute 1 - RMS amplitude\n",
    "\n",
    "Amplitude attributes can be extracted along mapped horizons or from time/depth windows. RMS amplitude is just one example of an amplitude attribute. In this exercise we are going to calculate RMS between a time window. This involves squaring the amplitudes within the window and summing them, then square rooting. \n",
    "\n",
    "https://wiki.seg.org/wiki/RMS_amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b926b-6bb3-4fbf-a009-2f056a08b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMS = np.zeros(data.shape)\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[1]):\n",
    "        trace = data[i,j,:]\n",
    "        \n",
    "        # Get RMS values\n",
    "        trace_sq = np.square(trace) # square \n",
    "        kernel = np.ones(11)/11 # range over which we take the RMS value\n",
    "        \n",
    "        # complete RMS calc\n",
    "        RMS_amp = np.sqrt(np.convolve(trace_sq, kernel, 'same'))\n",
    "        \n",
    "        #store results\n",
    "        RMS[i,j,:] = RMS_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b1829-f04b-4475-a8df-9da56045a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore3d(RMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0de1e-ab26-4754-a27e-d901f2da614e",
   "metadata": {},
   "source": [
    "## 4.1.2. Attribute 2 - 1st vertical derivative in time\n",
    "\n",
    "Any calculation you do with seismic data is a seismic attribute! New seismic attributes are invented all the time. You could invent your own! Some are really useful, and some less so... In this part of the exercise we will calcualte an attribute which is often found in seismic interpretation software- the 1st vertical derivative. This will highlight vertical gradients. Do you find this attribute highlights features any differently?\n",
    "\n",
    "https://primer-computational-mathematics.github.io/book/d_geosciences/remote_sensing/Image_Filtering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f42bb-0edd-4eb8-9783-be6f7957f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = np.zeros(data.shape)\n",
    "dt = (f.samples[1]-f.samples[0])\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[1]):\n",
    "        trace = data[i,j,:]\n",
    "\n",
    "        kernel = np.array([-1,1])/dt  #forward difference https://en.wikipedia.org/wiki/Finite_difference\n",
    "        \n",
    "        # complete RMS calc\n",
    "        diff = np.convolve(trace, kernel, 'same')\n",
    "        \n",
    "        #store results\n",
    "        diff1[i,j,:] = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ca38f-0925-4937-bf1b-2f8e66a5a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore3d(diff1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53acc5aa-5d6f-46db-9183-eed954c5d4dc",
   "metadata": {},
   "source": [
    "Please note the effect that our vm parameter has here when optimising our dynamic range! If you use the same dynamic range for both the effects become a lot clearer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc8b81-a23f-40dc-9bd9-2a3131f7a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "ax1 = plt.subplot(121)\n",
    "vm = np.percentile(data, 95)\n",
    "ax1.imshow(data[0,:,:].T, cmap='coolwarm', aspect='auto', vmin=-vm, vmax=vm)\n",
    "ax2 = plt.subplot(122)\n",
    "vm = np.percentile(diff1, 95)\n",
    "ax2.imshow(diff1[0,:,:].T, cmap='coolwarm', aspect='auto', vmin=-vm, vmax=vm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5a8cc-8e1a-46bf-8140-f8ac1a10340d",
   "metadata": {},
   "source": [
    "## 4.1.3.  Attribute 3 - 2nd vertical derivative in time\n",
    "\n",
    "...again, we can do any calculation we like with the data to design a new attribute. Do you find this one very helpful? Do any features become sharper/clearer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4274a5f6-bb8d-4f2a-9d23-1c609045ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff2 = np.zeros(data.shape)\n",
    "dt = (f.samples[1]-f.samples[0])\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[1]):\n",
    "        trace = data[i,j,:]\n",
    "\n",
    "        kernel = np.array([1,-2,1])/ (dt**2)  #second order central https://en.wikipedia.org/wiki/Finite_difference\n",
    "        \n",
    "        # complete RMS calc\n",
    "        diff = np.convolve(trace, kernel, 'same')\n",
    "        \n",
    "        #store results\n",
    "        diff2[i][j][:] = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e62047-2169-4c9f-9e87-09e44763c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore3d(diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f5bf7-484f-4357-9d1e-fb34adae0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "ax1 = plt.subplot(121)\n",
    "vm = np.percentile(data, 95)\n",
    "ax1.imshow(data[0,:,:].T, cmap='coolwarm', aspect='auto', vmin=-vm, vmax=vm)\n",
    "ax2 = plt.subplot(122)\n",
    "vm = np.percentile(diff2, 95)\n",
    "ax2.imshow(diff2[0,:,:].T, cmap='coolwarm', aspect='auto', vmin=-vm, vmax=vm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214d01-9fe2-468e-a4de-14d3b465fb4c",
   "metadata": {},
   "source": [
    "## 4.1.4.  Atrribute 4- Coherency\n",
    "\n",
    "As we discussed in lecture 6, discontinuity attributes are really important, and the algorithms to compute them are often trade-secrets in seismic interpretation software. In this part of the exercise we are using some code from a Github tutorial which shows a number of ways to calculate discontinuity attributes- https://github.com/seg/tutorials-2015/blob/master/1512_Semblance_coherence_and_discontinuity/writeup.md\n",
    "\n",
    "In this exercise we are going to use the \"marfurt semblance\". Semblance (also known as coherence) is a measure of how similar seismic traces are to each other. This code is slow... so we are only going to calculate coherence for a few time slices. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2344614-3cc1-4851-901f-9cbf7562363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_window(data, window, func):\n",
    "    # `generic_filter` will give the function 1D input. We'll reshape it for convinence\n",
    "    wrapped = lambda region: func(region.reshape(window))\n",
    "    \n",
    "    # Instead of an explicit for loop, we'll use a scipy function to do the same thing\n",
    "    # The boundaries will be handled by \"reflecting\" the data, by default\n",
    "    return scipy.ndimage.generic_filter(data, wrapped, window)\n",
    "\n",
    "def marfurt_semblance(region):\n",
    "    # We'll need an ntraces by nsamples array\n",
    "    # This stacks all traces within the x-y \"footprint\" into one\n",
    "    # two-dimensional array.\n",
    "    region = region.reshape(-1, region.shape[-1])\n",
    "    ntraces, nsamples = region.shape\n",
    "\n",
    "    square_of_sums = np.sum(region, axis=0)**2\n",
    "    sum_of_squares = np.sum(region**2, axis=0)\n",
    "    sembl = square_of_sums.sum() / sum_of_squares.sum()\n",
    "    return sembl / ntraces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181659d2-b9bb-4ce0-8363-e368ba090146",
   "metadata": {},
   "source": [
    "Due to the processing cost of coherency we will only be running this on 15 time-slices. You can run this for more layers if you like, but it may take a while. An applied eaxmple is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5618a60-3034-4173-8856-b303875e3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to processing cost we only run this on 15 layers\n",
    "marfurt = moving_window(data[:,:,100:115], (3, 3, 9), marfurt_semblance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdc381-3607-4218-bf22-6ea8c98b7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax1 = plt.subplot(121)\n",
    "vm = np.percentile(marfurt, 95)\n",
    "plt.imshow(marfurt[:,:,4].T, cmap='gray', aspect='auto', vmin=-vm, vmax=vm)\n",
    "plt.colorbar()\n",
    "ax2 = plt.subplot(122)\n",
    "vm = np.percentile(data, 95)\n",
    "plt.imshow(data[:,:,104].T, cmap='gray', aspect='auto', vmin=-vm, vmax=vm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30248a99-3c14-41d0-bfe1-7ef6c0f137fa",
   "metadata": {},
   "source": [
    "**Ex 2: Does coherency help better highlight the features you observed in 4.1.1? If you were a seismic interpreter would you rather interpret these fetures in the amplitude time slices (ie time slices through the original seismic) or the coherence?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1259a1d-c7ed-449c-8736-5c44be5c53a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "551cd1e4-03e0-47b6-ac04-c343bd1f6c93",
   "metadata": {},
   "source": [
    "**Ex 3 (optional): You could go a step further and take the derivative of the coherency volume above... remember, any calculation you do is a seismic attribute! You never know... you might design the next big seismic attribute!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb99b1-0d55-49bd-a60b-59423313de56",
   "metadata": {},
   "source": [
    "## 4.2. Attribute blending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b0c2a-2f81-4472-a64d-5322f3a75348",
   "metadata": {},
   "source": [
    "It can be useful to overlay two or more attributes using transparency to highlight features even further- this is called multi-attribute analysis. Let's first visualise two different attributes side by side to understand visually what is ocurring with some of these attributes and which features they are enhancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cdaab-d6df-4b0a-aad8-e050d646e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore3d_2(data_cube1, data_cube2, cmap1 = 'gray', cmap2 = 'gray'):\n",
    "    \"\"\"\n",
    "    code to visualise two data volumes together\n",
    "    \"\"\"\n",
    "    # https://github.com/seg/tutorials-2015/blob/master/1512_Semblance_coherence_and_discontinuity/Discontinuity_tutorial.ipynb\n",
    "    source1 = mlab.pipeline.scalar_field(data_cube1)\n",
    "    source1.spacing = [1, 1, -1]\n",
    "    \n",
    "    source2 = mlab.pipeline.scalar_field(data_cube2)\n",
    "    source2.spacing = [1, 1, -1]\n",
    "\n",
    "    nx, ny, nz = data_cube1.shape\n",
    "    \n",
    "    vm = np.percentile(data_cube1, 95)\n",
    "    mlab.pipeline.image_plane_widget(source1, plane_orientation='x_axes', \n",
    "                                     slice_index=nx//2, colormap= cmap1, vmin=-vm, vmax=vm, plane_opacity=0.1)\n",
    "    mlab.pipeline.image_plane_widget(source1, plane_orientation='y_axes', \n",
    "                                     slice_index=ny//2, colormap= cmap1, vmin=-vm, vmax=vm, plane_opacity=0.1)\n",
    "    mlab.pipeline.image_plane_widget(source1, plane_orientation='z_axes', \n",
    "                                     slice_index=nz//2, colormap= cmap1, vmin=-vm, vmax=vm, plane_opacity=0.1)\n",
    "    \n",
    "    vm = np.percentile(data_cube2, 95)\n",
    "    mlab.pipeline.image_plane_widget(source2, plane_orientation='x_axes', \n",
    "                                     slice_index=nx//2, colormap= cmap2, vmin=-vm, vmax=10)\n",
    "    mlab.pipeline.image_plane_widget(source2, plane_orientation='y_axes', \n",
    "                                     slice_index=ny//2, colormap= cmap2, vmin=-vm, vmax=vm)\n",
    "    mlab.pipeline.image_plane_widget(source2, plane_orientation='z_axes', \n",
    "                                     slice_index=nz//2, colormap= cmap2, vmin=-vm, vmax=vm)\n",
    "    \n",
    "    mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f134cce-1a1f-4875-bedb-cdf896a31f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore3d_2(data, RMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f15f6d-3035-42ea-afdb-8454f01d3fbb",
   "metadata": {},
   "source": [
    "An alternative way to use attributes together would be by simply plotting them over each other with the top layer with a higher transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1458a-e3a9-43fe-b4b3-6f7af5e82272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create our own colorbar for clearer results\n",
    "cmap = matplotlib.colors.ListedColormap(['red','white'])\n",
    "bounds=[0,0.5,1]\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a99da-8e9b-4c0e-96fd-0dcc64f66181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot two datasets together\n",
    "vm = np.percentile(data, 95)\n",
    "plt.imshow(data[:,:,104].T, cmap='gray', aspect='auto', vmin=-vm, vmax=vm)\n",
    "\n",
    "vm = np.percentile(marfurt, 99)\n",
    "plt.imshow(marfurt[:,:,4].T, cmap=cmap, aspect='auto', alpha = 0.5) # alpha controls transparency\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01653b7f-4397-44bb-b33b-2a6cffdd4bd2",
   "metadata": {},
   "source": [
    "Lastly, something commonly done in seismic interpretation is RGB blending. To achieve this every attribute is assigned either a Red, Blue, or Green colour and these layers and then stacked to produce a color image output that contains information of all 3 attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ee106-044c-4c28-85f1-02aff6efba10",
   "metadata": {},
   "source": [
    "**EX 4: Repeat this exercise but with the TNW_small_2 datset we looked at in Exercise 3. Can you reveal any geological features better with attributes than you could with the original seismic volume in Exercise 3?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
